---
title: "Setting alerts in SigNoz"
---

## Setting Alert Rules[](#setting-alert-rules "Direct link to Setting Alert Rules")

You can set Alert Rules in SigNoz in the following 3 ways:

1. Query Builder - This is DIY way to build alerts by selecting metrics from dropdowns. You can also set filter and group by conditions by selecting options from the dashboard.
2. PromQL - You can use [Prometheus Query Language](https://prometheus.io/docs/prometheus/latest/querying/basics/) to write expressions for alerts which will be evaluated in regular time interval. If you have set up alerts in Prometheus, this method should be very familiar.
3. Clickhouse Queries - You can write clickhouse queries that adhere to the SigNoz data model and format. The result of the query will be used to evaluate alert threshold conditions. Additionally, you can also generate labels and annotations using the results of your query.

Navigate to Alerts page from the left panel. It has 2 tabs:

1. Alert Rules
2. Triggered Alerts

Alert Rules set the expression you want to evaluate to start firing alerts. The Alert Rules tab shows a list of currently configured alert rules and labels like `severity` and `Alert Name`. It also shows the current status of this Alert rules. If any alerts are `firing` because of this or everything is `Ok`

<Frame>![alert-rules](/images/alert-rules-5d7f2c0a3ee964ca74cd3db4481659b6.webp)</Frame>

### Steps to Create Alert Rules:[](#steps-to-create-alert-rules "Direct link to Steps to Create Alert Rules:")

To create new alert rules, you can click the `New Alerts` button. This would open a pane with the type of alerts. 

<Frame>![image](/images/208090898-2a05a349-c071-47e1-9dd3-d0a5de70f113.png)</Frame>

Choose an appropriate type of alert by clicking on one of the cards. 

On the alert form, you can choose one of the following tabs to define source of your metric. 

1. Query Builder
2. Clickhouse Query
3. PromQL (Available only for metrics)

<Note>
   Presently the logs, traces and exceptions-based alerts support only Clickhouse Query based metric. 
</Note>

#### 1\. Query Builder[](#1-query-builder "Direct link to 1. Query Builder")

In Query Builder, you can use the dropdowns in the dashboard to select the right metric. 

* Then create an expression with WHERE and GROUPBY clauses which represents the expression to evaluate for alerting
* Threshold which the value of expression should cross ( above or below) to trigger an alert.
* Evaluation period of the expression
* Set name, descriptions and tags about the alert to make it more informative

<Frame>![alerts-query-builder](/images/alerts-query-builder-8d096f4612267d95ec650fe3af603b4d.webp)</Frame>

#### 2\. PromQL[](#2-promql "Direct link to 2. PromQL")

In PromQL, you can write the Prometheus expression to evaluate. 

* Set the expression you want to evaluate to trigger alerts. The expression also includes the evaluation interval.
* Threshold which the value of expression should cross ( above or below) to trigger an alert.
* Set labels like `severity` to communicate how severe the issue is if this alert starts firing

<Frame>![prometheus-alert-rules](/images/promql-alerts-2a1aa2d06e4e04d1d1911a228af7967e.webp)</Frame>

#### 3\. Writing Clickhouse Queries in Alert form[](#3-writing-clickhouse-queries-in-alert-form "Direct link to 3. Writing Clickhouse Queries in Alert form")

On `clickhouse query` tab, you will be presented with a query editor with a default query that you can start working with. To learn more about the data-model and query format, read [this tutorial](https://signoz.io/docs/tutorial/writing-clickhouse-queries-in-dashboard/#building-alert-queries-with-clickhouse-data). 

<Frame>![image](/images/208092689-07e7edd6-2277-4cd4-9fbf-a2e13531a4a9.png)</Frame>

You can use `Run Query` to confirm your query works. Include the bind variables and mandatory column aliases as mentioned [here](https://signoz.io/docs/tutorial/writing-clickhouse-queries-in-dashboard/#building-alert-queries-with-clickhouse-data). 

### Steps to Setup Triggered Alerts[](#steps-to-setup-triggered-alerts "Direct link to Steps to Setup Triggered Alerts")

Triggered alerts show the alerts which are in `firing` or `pending` state. 

Pending means that the rule threshold is crossed, but it is still waiting based on the specified time period. Once the specified time is passed, the alert starts firing.

It also has different tags like alert name, severity, since when the alert started firing, etc.

<Frame>![triggered-alerts](/images/triggered-alerts-3b6a06e2573f6a04e33e1b9c7e8fc7e5.webp)</Frame>

* Filtering and grouping Triggered alerts

You can also filter and group triggered alerts based on tags. The filtering field accepts multiple key-value pairs like `serverity:warning`

For grouping, you can use any of the tags like `severity`, `alertname` or any other label you would have specified in your alert rule. You can use the grouping feature to group the list of triggered alerts based on these tags.

<Frame>![triggered-alerts-groups](/images/triggered-alerts-groups-e88d1362a89bbc1219f8faef251b9eae.webp)</Frame>

## Setting up a Notification channel[](#setting-up-a-notification-channel "Direct link to Setting up a Notification channel")

You can setup notification channels for sending the generated alerts to other applications. Currently, the following channels are supported: 

* Slack ([v0.5.0](https://github.com/SigNoz/signoz/releases/tag/v0.5.0) onwards)
* Webhook ([v0.7.4](https://github.com/SigNoz/signoz/releases/tag/v0.7.4) onwards)
* PagerDuty ([v0.8.0](https://github.com/SigNoz/signoz/releases/tag/v0.8.0) onwards)
* MS Teams ([v0.26.0](https://github.com/SigNoz/signoz/releases/tag/v0.26.0) onwards)
* Opsgenie ([v0.28.0](https://github.com/SigNoz/signoz/releases/tag/v0.28.0) onwards)

We are also working towards adding more channels (like Email) in the upcoming releases.

The alert channel tabs can be accessed from `Settings > Alert Channels` tab. This shows a list of configured alert channels. When multiple channels are setup, the alerts will be sent to all the configured channels.

<Frame>![alert-channels](/images/alert-channels-99bfba39b84b765012b07ac2fae90c0a.webp)</Frame>

### 1\. Configure Slack Channel[](#1-configure-slack-channel "Direct link to 1. Configure Slack Channel")

#### a. Prerequisite[](#a-prerequisite "Direct link to a. Prerequisite")

For setting up Slack as a notification channel, you need to first configure an Incoming Webhook in Slack. The following article explains how to do that - [Sending messages to slack using Incoming Webhook](https://api.slack.com/messaging/webhooks)

#### b. Creating a new Notification channel (Slack)[](#b-creating-a-new-notification-channel-slack "Direct link to b. Creating a new Notification channel (Slack)")

You have to provide a name, webhook URL and channel name (with # prefix) to configure a notification channel. You may use [go templates](https://prometheus.io/docs/alerting/latest/notifications/) for the title and description. 

<Frame>![new-notification-channel](/images/new-notification-channel-5520d5f2e2ce51d76fd96d47fabb660e.webp)</Frame>

You can also verify the configuration by using the _Test_ button. When you click _Test_, a test alert will be sent to the configured slack channel. The purpose of this feature is to confirm that signoz alert manager can talk to your webhook URL. 

#### c. Editing a Notification channel (Slack)[](#c-editing-a-notification-channel-slack "Direct link to c. Editing a Notification channel (Slack)")

You can edit slack webhook URL or other parameters except the channel name and channel type. 

<Frame>![edit-notification-channel](/images/edit-notification-channel-f74c0c0134831e43834287cab8fe0f7f.webp)</Frame>

#### d. Receive Alert in Slack[](#d-receive-alert-in-slack "Direct link to d. Receive Alert in Slack")

Once everything is set up correctly, you should see your alerts in the configured slack channel whenever the monitored metrics cross the threshold specified in the alert rules.

Now you can stay relaxed that SigNoz will promptly alert you whenever something goes wrong in any of your applications or infra components.

<Frame>![alerts-in-slack](/images/alerts-in-slack-051d42cc4aeb7825ecf8247fed80e6b0.webp)</Frame>

### 2\. Configure Webhook Channel[](#2-configure-webhook-channel "Direct link to 2. Configure Webhook Channel")

#### a. Prerequisite[](#a-prerequisite-1 "Direct link to a. Prerequisite")

You must have a valid webhook URL (reachable from SigNoz Alert Manager) and an application ready to accept webhook messages.

#### b. Creating a new Webhook channel[](#b-creating-a-new-webhook-channel "Direct link to b. Creating a new Webhook channel")

Enter Webhook URL endpoint, username and password (if needed). Use _Test_ button to test the connection with your application. 

<Frame>![image](/images/165084693-8034b65a-f0f4-4ff4-8a72-88fb7b8726b4.png)</Frame>

#### c. Editing a Webhook channel[](#c-editing-a-webhook-channel "Direct link to c. Editing a Webhook channel")

Similar to slack, you can edit most of the webhook parameters except the channel name and type. 

<Frame>![image](/images/165084529-bf0aa817-5c4e-4f45-98bd-eeb33eb02547.png)</Frame>

#### d. Receive Alert through Webhook[](#d-receive-alert-through-webhook "Direct link to d. Receive Alert through Webhook")

<Frame>![image](/images/165078852-d3ae7571-bfa2-409a-93aa-2a870b379cb1.png)</Frame>

#### e. Sample format of a Webhook message[](#e-sample-format-of-a-webhook-message "Direct link to e. Sample format of a Webhook message")

A webhook message may contain multiple alerts. By default, the SigNoz alert manager groups alerts by the alert name and delivers the grouped messages every 5 minutes. 

For resolved alerts, the alert manager will send the time of resolution in _endsAt_. You can also use fingerprint property to identify and process updates sent by alert manager. 

```json
{
   "receiver":"w1",
   "status":"firing",
   "alerts":[
      {
         "status":"firing",
         "labels":{
            "alertname":"DiskRunningFull",
            "dev":"sda3",
            "instance":"example3",
            "severity":"critical"
         },
         "annotations":{
            "info":"The disk sda3 is running full",
            "summary":"please check the instance example1"
         },
         "startsAt":"2022-04-25T14:35:19.490146+05:30",
         "endsAt":"0001-01-01T00:00:00Z",
         "generatorURL":"",
         "fingerprint":"ad592b0afcbe2e79"
      }
   ],
   "groupLabels":{
      "alertname":"DiskRunningFull"
   },
   "commonLabels":{
      "alertname":"DiskRunningFull",
      "dev":"sda3",
      "instance":"example3",
      "severity":"critical"
   },
   "commonAnnotations":{
      "info":"The disk sda3 is running full",
      "summary":"please check the instance example1"
   },
   "externalURL":"http://Apples-MacBook-Pro-3.local:9093",
   "version":"4",
   "groupKey":"{}/{}:{alertname=\"DiskRunningFull\"}",
   "truncatedAlerts":0
}

```

### 3\. Configure PagerDuty Channel[](#3-configure-pagerduty-channel "Direct link to 3. Configure PagerDuty Channel")

There are two ways to integrate with PagerDuty: via global [event orchestration](https://support.pagerduty.com/docs/event-orchestration) or directly through an integration on [pagerduty service](https://support.pagerduty.com/docs/services-and-integrations). Integrating alerts with global event orchestration is beneficial if you want to automate incident creation or management. 

#### a. Get Integration or Routing key to integrate with event orchestration[](#a-get-integration-or-routing-key-to-integrate-with-event-orchestration "Direct link to a. Get Integration or Routing key to integrate with event orchestration")

1. From the **Automation** menu, select **Event Orchestration**
2. Create a new orchestration
3. Click on **Global Orchestration Key**, copy your **integration key** and keep it safe for later use.

<Frame>![image](/images/180833019-c865ecd5-f752-419f-998e-baf296daef88.png)</Frame>

#### b. Get Integration or Routing key to integrate with pagerduty service[](#b-get-integration-or-routing-key-to-integrate-with-pagerduty-service "Direct link to b. Get Integration or Routing key to integrate with pagerduty service")

1. Go to **Services > Service Directory** and select the **service** where youâ€™d like to add the integration.
2. Select **Integration tab** and click **Add another integration**
3. Select **Events API V2** from the list
4. Click **Add**
5. Find your integration in the list and click down arrow to view and copy integration key (aka routing key)

For more details on PagerDuty service setup, visit [here](https://support.pagerduty.com/docs/services-and-integrations#add-integrations-to-an-existing-service).

<Frame>![image](/images/179944431-4e7ebb09-c6ca-455f-88b5-02e0f7ccfd8a.png)</Frame>

#### c. Prerequisite[](#c-prerequisite "Direct link to c. Prerequisite")

You must have a valid Integration Key (aka Routing Key) before you setup a PagerDuty channel in SigNoz Dashboard. 

#### d. Create a new PagerDuty channel[](#d-create-a-new-pagerduty-channel "Direct link to d. Create a new PagerDuty channel")

1. Go to **Settings > Alert Channels**
2. Click **New Channel**
3. Enter a **name** and select **PagerDuty** as channel type
4. Enter **Routing Key (aka Integration Key)** obtained from pagerduty (described at the start of this section)
5. Enter more information as necessary. More details on the fields can be found [here](https://developer.pagerduty.com/docs/ZG9jOjExMDI5NTgw-events-api-v2-overview). You may also use [go templates](https://prometheus.io/docs/alerting/latest/notifications/) for dynamically setting the fields.
6. Test the connect with **Test** button
7. **Save** the channel

<Frame>![image](/images/179944648-a9f3b558-2687-4132-a6ce-bc5d69f59368.png)</Frame>

#### e. Test the PagerDuty channel[](#e-test-the-pagerduty-channel "Direct link to e. Test the PagerDuty channel")

1. Let's create a simple alert rule that monitors average CPU performance for each host. Go to **Alerts** page in **your SigNoz app** and click `New Alert` button. When the new alert page opens, edit metric query as shown below. Feel free to choose any other metric, the idea is to pick a metric with sufficient data to raise an alert.  
<Frame>![image](/images/179949345-f242f0da-2afb-4041-ab72-3390d645dd77.png)</Frame>
2. We can now **review the graph** to identify a threshold that will definitely cause an alert. Here, anything below 0.2 looks like a good condition for threshold.  
<Frame>![image](/images/179957078-b7e430ab-95c2-4d5d-8eac-10670f1e0e52.png)</Frame>
1. Let's **set threshold to 0.12** to be sure that alert will be raised in next few minutes.  
<Frame>![image](/images/179949589-17cab9a8-640d-422a-a22a-f4e5ebd6f5c7.png)</Frame>
2. **Save the alert** rule. Feel free to edit severity and labels as necessary.
3. Go to your **PagerDuty Alerts Dashboard** (`PagerDuty Home >> Incident >> Alerts`) and wait for a few minutes. If all goes well, you will **see an incident**. You may have to refresh the page few times to see the alert.  
<Frame>![image](/images/179956540-0eae3553-c813-4d39-8484-bba2c6d939c5.png)  </Frame>
<Frame>![image](/images/179956567-d4de2d44-4510-46bb-80df-13ecefc08064.png)</Frame>

### 4\. Configure Opsgenie Channel[](#4-configure-opsgenie-channel "Direct link to 4. Configure Opsgenie Channel")

#### a. Prerequisite[](#a-prerequisite-2 "Direct link to a. Prerequisite")

First we need to create an integration in Opsgenie, and obtain an API key. Follow the steps written [here](https://support.atlassian.com/opsgenie/docs/integrate-opsgenie-with-prometheus/) to create an integration and obtain an API key.

#### b. Creating a new Notification channel (Opsgenie)[](#b-creating-a-new-notification-channel-opsgenie "Direct link to b. Creating a new Notification channel (Opsgenie)")

You have to provide a name, API Key to configure a notification channel. You may use [go templates](https://prometheus.io/docs/alerting/latest/notifications/) for the message, description, and priority.

<Frame>![new-notification-channel](/images/opsgenie-new-channel-56cdc8b8e0dc844115e4aa96319bd30b.png)</Frame>

You can also verify the configuration by using the _Test_ button. When you click _Test_, a test alert will be sent. The purpose of this feature is to confirm that signoz alert manager can talk to your opsgenie.

#### c. Editing a Notification channel (Opsgenie)[](#c-editing-a-notification-channel-opsgenie "Direct link to c. Editing a Notification channel (Opsgenie)")

You can edit opsgenie API Key or other parameters except the channel name and channel type.

#### d. Receive Alert in Opsgenie[](#d-receive-alert-in-opsgenie "Direct link to d. Receive Alert in Opsgenie")

Once everything is set up correctly, you should see the alerts in the opsgenie Alerts whenever the monitored metrics cross the threshold specified in the alert rules.

Now you can stay relaxed that SigNoz will promptly alert you whenever something goes wrong in any of your applications or infra components.

<Frame>![alert-in-opsgenie](/images/alert-in-opsgenie-ed49aa1c9bcecc39cc2c9e02823b7b92.png)</Frame>

### 5\. Configure MS Teams Channel[](#5-configure-ms-teams-channel "Direct link to 5. Configure MS Teams Channel")

#### a. Prerequisite[](#a-prerequisite-3 "Direct link to a. Prerequisite")

First we need to create an incoming webhook in MS Teams, and obtain a webhook URL. Follow the steps written [here](https://docs.microsoft.com/en-us/microsoftteams/platform/webhooks-and-connectors/how-to/add-incoming-webhook) to create an incoming webhook and obtain a webhook URL.

#### b. Creating a new Notification channel (MS Teams)[](#b-creating-a-new-notification-channel-ms-teams "Direct link to b. Creating a new Notification channel (MS Teams)")

You have to provide a name, webhook URL to configure a notification channel. You may use [go templates](https://prometheus.io/docs/alerting/latest/notifications/) for the title and description.

<Frame>![new-notification-channel](/images/ms-teams-new-channel-5937a372f2b56c44e57b78c3bbfc2941.png)</Frame>

You can also verify the configuration by using the _Test_ button. When you click _Test_, a test alert will be sent. The purpose of this feature is to confirm that signoz alert manager can talk to your MS Teams.

#### c. Editing a Notification channel (MS Teams)[](#c-editing-a-notification-channel-ms-teams "Direct link to c. Editing a Notification channel (MS Teams)")

You can edit MS Teams webhook URL or other parameters except the channel name and channel type.

#### d. Receive Alert in MS Teams[](#d-receive-alert-in-ms-teams "Direct link to d. Receive Alert in MS Teams")

Once everything is set up correctly, you should see the alerts in the MS Teams Alerts whenever the monitored metrics cross the threshold specified in the alert rules.

Now you can stay relaxed that SigNoz will promptly alert you whenever something goes wrong in any of your applications or infra components.

<Frame>![alert-in-ms-teams](/images/alert-in-ms-teams-c9ebf9047293adb42f83bdb3ea30bb9c.png)</Frame>

<br />

<Note>
   If you encounter any unexpected challenges during the use of this integration, please contact SigNoz Support at [\[email protected\]](/cdn-cgi/l/email-protection#cbb8bebbbba4b9bf8bb8a2aca5a4b1e5a2a4)
</Note>